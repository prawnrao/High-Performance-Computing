{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matrix multiplication in PyOpenCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will learn how to implement a simple matrix multiplication in OpenCL. Please note that there are good libraries available to handle this, such as [MAGMA](http://icl.cs.utk.edu/magma/software/) or [clBLAS](https://github.com/clMathLibraries/clBLAS). In practice, we should always use well-tested standard solutions if available. The example presented below has been adapted from https://cnugteren.github.io/tutorial/pages/page1.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we should first install an OpenCL environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import pyopencl. We also need Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to multiply two matrices of dimension 2048. For a first implementation, we assume both matrices to be square and of fixed size. The following command creates two random matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2048\n",
    "dtype='float32'\n",
    "A = np.random.randn(n, n).astype(dtype)\n",
    "B = np.random.randn(n, n).astype(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load these arrays onto the device and create space for the result output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "mf = cl.mem_flags\n",
    "a_device = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=A)\n",
    "b_device = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=B)\n",
    "c_device = cl.Buffer(ctx, mf.WRITE_ONLY, A.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to measure the CPU time using the Numpy product. For timing comparisons we first define our usual Timer class again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:    \n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20166397094726562\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    C = A.dot(B)\n",
    "print(t.interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how a matrix multiplication works. We have a triple for loop of the form\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "   \n",
    "The most trivial way to parallelize the execution is to handle the two outer loops in parallel and have the inner loop be handled by the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = \"\"\"\n",
    "__kernel void simple_matmul(const int N,\n",
    "                          const __global float* A,\n",
    "                          const __global float* B,\n",
    "                          __global float* C){\n",
    "        // Thread identifiers\n",
    "        const int globalRow = get_global_id(0);\n",
    "        const int globalCol = get_global_id(1);\n",
    "        // Compute a single element (loop over K)\n",
    "        float acc = 0.0f; \n",
    "        for (int k=0; k<N; k++)\n",
    "            acc += A[N * globalRow + k] * B[N * k + globalCol];\n",
    "        // Store the result\n",
    "        C[globalRow*N + globalCol] = acc;\n",
    "        }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prg = cl.Program(ctx, kernel).build()\n",
    "simple_matmul = prg.simple_matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    event = simple_matmul(queue, (n, n), (1, 1), np.int32(n), a_device, b_device, c_device)\n",
    "    event.wait()\n",
    "print(t.interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution is quite slow. One issue is that we have a lot of load operations from the global memory compared to the computations. This is not an issue on machines with large and sophisticated caches (such as an Intel Xeon). The following kernel proceeds by creating work groups and assigning subblocks to each workgroup.\n",
    "\n",
    "In the following we define the local work group size through the C macro *TS*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = \"\"\"\n",
    "__kernel void blocked_matmul(const int N,\n",
    "                      const __global float* A,\n",
    "                      const __global float* B,\n",
    "                      __global float* C) {\n",
    "                      \n",
    "    // Thread identifiers\n",
    "    const int row = get_local_id(0); // Local row ID (max: TS)\n",
    "    const int col = get_local_id(1); // Local col ID (max: TS)\n",
    "    const int globalRow = TS*get_group_id(0) + row; // Row ID of C (0..M)\n",
    "    const int globalCol = TS*get_group_id(1) + col; // Col ID of C (0..N)\n",
    " \n",
    "    // Local memory to fit a tile of TS*TS elements of A and B\n",
    "    __local float Asub[TS][TS];\n",
    "    __local float Bsub[TS][TS];\n",
    " \n",
    "    // Initialise the accumulation register\n",
    "    float acc = 0.0f;\n",
    "    \n",
    "    // Loop over all tiles\n",
    "    const int numTiles = N/TS;\n",
    "    for (int t=0; t<numTiles; t++) {{\n",
    " \n",
    "        // Load one tile of A and B into local memory\n",
    "        const int tiledRow = TS*t + row;\n",
    "        const int tiledCol = TS*t + col;\n",
    "        Asub[row][col] = A[tiledCol + N * globalRow];\n",
    "        Bsub[row][col] = B[globalCol + tiledRow * N];\n",
    " \n",
    "        // Synchronise to make sure the tile is loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    " \n",
    "        // Perform the computation for a single tile\n",
    "        for (int k=0; k<TS; k++) {{\n",
    "            acc += Asub[row][k] * Bsub[k][col];\n",
    "        }}\n",
    " \n",
    "        // Synchronise before loading the next tile\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }}\n",
    " \n",
    "    // Store the final result in C\n",
    "    C[globalCol + globalRow * N] = acc;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 4\n",
    "prg = cl.Program(ctx, kernel).build(options=['-D', 'TS={0}'.format(ts)])\n",
    "blocked_matmul = prg.blocked_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.015583038330078\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    event = blocked_matmul(queue, (n, n), (ts, ts), np.int32(n), a_device, b_device, c_device)\n",
    "    event.wait()\n",
    "print(t.interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now easy to experiment with different work group sizes. Optimal work group sizes depend on the details of the underlying architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "OpenCL nows vector variables of the type `float2`, `float4`, etc. These store multiple floats at the same time and can often be better optimized by the underlying runtime system for the in-built SIMD architecture. Check out the OpenCL standard to learn about these vector types and try to use them in the kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
